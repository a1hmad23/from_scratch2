{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6857caeb-5575-432a-b526-1250094d7420",
   "metadata": {},
   "source": [
    "# Mathematical Forumulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195e30c3-3981-4048-84f3-be22755a572e",
   "metadata": {},
   "source": [
    "- Suppose we have $m$ features and $n$ training examples.  \n",
    "  Then, our model predicts:\n",
    "\n",
    "$$\n",
    "\\hat{y}_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\dots + \\beta_m x_{im}, \n",
    "\\quad i = 1, \\dots, n\n",
    "$$\n",
    "\n",
    "- Let\n",
    "\n",
    "$$\n",
    "\\hat{Y} =\n",
    "\\begin{pmatrix}\n",
    "\\hat{y}_1 \\\\\n",
    "\\hat{y}_2 \\\\\n",
    "\\vdots \\\\\n",
    "\\hat{y}_n\n",
    "\\end{pmatrix}.\n",
    "$$\n",
    "\n",
    "Then, in **matrix form** we can write:\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "\\hat{y}_1 \\\\\n",
    "\\hat{y}_2 \\\\\n",
    "\\vdots \\\\\n",
    "\\hat{y}_n\n",
    "\\end{pmatrix}\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "1 & x_{11} & x_{12} & \\dots & x_{1m} \\\\\n",
    "1 & x_{21} & x_{22} & \\dots & x_{2m} \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "1 & x_{n1} & x_{n2} & \\dots & x_{nm}\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "\\beta_0 \\\\\n",
    "\\beta_1 \\\\\n",
    "\\vdots \\\\\n",
    "\\beta_m\n",
    "\\end{pmatrix}.\n",
    "$$\n",
    "\n",
    "- Here:\n",
    "  - The feature  $\\boldsymbol{X}$  (of shape $( n \\times (m+1)$ )) contains all training examples.  \n",
    "  - The weight vector $\\boldsymbol{\\beta}$ (of shape $( (m+1) \\times 1)$ contains the model coefficients.\n",
    "  - The predicted outputs $\\boldsymbol{\\hat{Y}}$  (of shape $( n \\times 1)$ are obtained as $$\\boldsymbol{\\hat{Y} = X {\\beta}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7bb4d8-3cbc-4cfd-8af1-bec4f4d7346b",
   "metadata": {},
   "source": [
    "## Loss Function\n",
    "The sum of residual squares is $\\sum_{i=0}^n (y_{i} - \\hat{y}_{i})^2$ where $y_{i}\\epsilon \\boldsymbol{Y}$ and $\\hat{y}_{i} \\epsilon \\boldsymbol{\\hat{Y}}$. \n",
    "Thus, we have $$\n",
    "J = (\\boldsymbol{Y}-\\boldsymbol{\\hat{Y}})^T(\\boldsymbol{Y}-\\boldsymbol{\\hat{Y}})\n",
    "$$\n",
    "Expanding the RHS, we get: $$\\boldsymbol{Y^TY}-\\boldsymbol{Y^T\\hat{Y}}-\\boldsymbol{\\hat{Y}^TY}-\\boldsymbol{\\hat{Y}^T \\hat{Y}}$$\n",
    "Since both $\\boldsymbol{Y}$ and $\\boldsymbol{\\hat{Y}}$ are matrices of shape $(n, 1)$, that is, vectors, the terms are $\\boldsymbol{Y^T\\hat{Y}}$ and $\\boldsymbol{\\hat{Y}^TY}$ are both just scalars, and hence, symmetric. Thus, we have $$\n",
    "J = \\boldsymbol{Y^TY}-2\\boldsymbol{Y^T\\hat{Y}}-\\boldsymbol{\\hat{Y}^T \\hat{Y}}\n",
    "$$\n",
    "Now, inputting $\\boldsymbol{\\hat{Y} = X {\\beta}}$, we get:\n",
    "$$\n",
    "J(\\boldsymbol{\\beta}) = \\boldsymbol{Y^TY}-2\\boldsymbol{Y^TX\\beta} - \\boldsymbol{\\beta ^TX^TX\\beta}\n",
    "$$\n",
    "where $\\boldsymbol{\\beta ^TX^T}= \\boldsymbol{(X\\beta)^T}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16aec620-590f-4044-8d45-89992cacc0eb",
   "metadata": {},
   "source": [
    "## Minimizing the loss function\n",
    "We need $\\boldsymbol{\\beta}$ such that $J(\\boldsymbol{\\beta})$ is minimized. To this end, we differentiate $J$ and set is derivative to $0$. $$\n",
    " \\frac{\\partial J(\\boldsymbol{\\beta})}{\\partial \\boldsymbol{\\beta}} = 0 - 2\\boldsymbol{Y^TX} - 2 \\boldsymbol{\\beta^TX^T X}\n",
    "$$\n",
    "Where the third term was found using the identity $\\frac{\\partial (\\beta^TA\\beta)}{\\partial \\beta } = (A+A^T)\\beta = 2\\beta A$ , where the second step follows since $\\boldsymbol{A} = \\boldsymbol{X^TX}$ is symmetric.\n",
    "\n",
    "Thus, we have $$\n",
    "\\boldsymbol{Y^TX} = \\boldsymbol{\\beta^TX^T X}\n",
    "$$$$\n",
    "\\boldsymbol{\\beta^T} = \\boldsymbol{Y^TX(X^TX)^{-1}}\n",
    "$$\n",
    "$$\n",
    "\\boldsymbol{\\beta} = \\boldsymbol{[(X^TX)^{-1}]^T X^TY}\n",
    "$$\n",
    "since $\\boldsymbol{X^TX}$ is symmetric, we have\n",
    "$$\n",
    "\\boldsymbol{\\beta} = \\boldsymbol{(X^TX)^{-1} X^TY}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39270bc4-14dd-4a5e-928e-eef1ca7b4a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class CustomLinearRegressor:\n",
    "    def __init__(self):\n",
    "        self.beta = None\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        n = X_train.shape[0]\n",
    "        X = np.concatenate((np.ones((n, 1)), X_train), axis=1)\n",
    "        self.beta = np.linalg.inv(X.T @ X) @ X.T @ y_train\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        n = X_test.shape[0]\n",
    "        X = np.concatenate((np.ones((n, 1)), X_test), axis=1)\n",
    "        return X @ self.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b78494b-1644-430c-aa44-e829ad2c25eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X, y = make_regression(n_samples=100, n_features=2, n_informative=2, n_targets=1, noise=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb1e63bb-53c3-4147-a652-a6be6084771c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.251678</td>\n",
       "      <td>-2.103232</td>\n",
       "      <td>-46.145934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>-0.882336</td>\n",
       "      <td>-0.971738</td>\n",
       "      <td>-150.088081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1.875331</td>\n",
       "      <td>0.380150</td>\n",
       "      <td>78.699235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>-1.011850</td>\n",
       "      <td>0.115377</td>\n",
       "      <td>-23.836923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.549113</td>\n",
       "      <td>0.931258</td>\n",
       "      <td>163.291496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature1  feature2      target\n",
       "26  1.251678 -2.103232  -46.145934\n",
       "46 -0.882336 -0.971738 -150.088081\n",
       "99  1.875331  0.380150   78.699235\n",
       "81 -1.011850  0.115377  -23.836923\n",
       "15  1.549113  0.931258  163.291496"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'feature1': X[:, 0], 'feature2': X[:, 1], 'target':y})\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "089115b2-3202-47ca-90eb-1d834b32d19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "749cc0d1-cda4-4041-ac77-3d9d67154915",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_lr = CustomLinearRegressor()\n",
    "custom_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65e4f909-e398-494d-9fca-7c7594ae88c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = custom_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "228775ae-6728-4f78-9d46-18a9d34b4591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((y_true - y_pred)**2))\n",
    "\n",
    "def r2_score(y_true, y_pred):\n",
    "    ss_lr = np.sum((y_true - y_pred)**2)\n",
    "    ss_m = np.sum((y_true - np.mean(y_true))**2)\n",
    "    return 1 - ss_lr/ss_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "227a167f-7c50-419b-8812-ae55c669fe55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.53060006119548\n",
      "0.75784075038077\n"
     ]
    }
   ],
   "source": [
    "print(rmse(y_test, y_preds))\n",
    "print(r2_score(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "60783492-d119-4d10-b44d-81d75ea7efa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.17128145, 69.18110011, 78.20907969])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_lr.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e388b4e-9e69-4bc5-a08c-b1d8f831738d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (from_scratch2)",
   "language": "python",
   "name": "from_scratch2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
