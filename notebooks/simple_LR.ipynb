{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "325cab69-d94f-475b-b188-b0b8ffe207e0",
   "metadata": {},
   "source": [
    "# Simple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b38c469-962b-46e6-8fca-dd9e3cc3c801",
   "metadata": {},
   "source": [
    "## Closed-Form Solution Derivation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57fd756-6e81-4673-83ff-2b160e2309f2",
   "metadata": {},
   "source": [
    "Given observations $(x_{i}, y_{i})$ for $i=1,\\dots, n$, we postulate a linear relationship between the independent variable $x$ and the dependent variable $y$: $$\n",
    "y_{i} = mx_{i} + b\n",
    "$$ We want a line of best fit, so, we want to minimize the sum of square errors: $$\n",
    "J(\\hat{y}_{i},y_{i} )=\\sum_{i=0}^n (y_{i}-\\hat{y}_{i})^2\n",
    "$$\n",
    "Where $\\hat{y}_{i}$ is the prediction $mx_{i}+b$ for values of $m$ and $b$ that minimize the above function $J$.\n",
    "\n",
    "To find the required values of $m$ and $b$, we rewrite the sum of square errors in terms of them, and set both of its partial derivatives to $0$, as that is where we will find it's minimum:\n",
    "\n",
    "Derivative with respect to $b$: \n",
    "$$\n",
    "0 = \\frac{\\partial J(m, b)}{\\partial b} = 2\\sum_{i=0}^n(y_{i}-mx_{i}-b) \\quad\\Rightarrow\\quad \\sum_{i=0}^n y_{i} = nb + m \\sum_{i=0}^nx_{i}\n",
    "$$\n",
    "- Dividing by $n$ and solving for $b$ gives us: $$\n",
    "\\bar{y} - m \\bar{x} = b\n",
    "$$\n",
    "where $\\bar{y}$ and $\\bar{x}$ are the average values of the observations $y_{i}$ and $x_{i}$, respectively. \n",
    "\n",
    "Derivative with respect to $m$:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial m}=-2\\sum_{i=1}^n x_i\\big(y_i-mx_i-b\\big)=0\n",
    "\\;\\;\\Longrightarrow\\;\\;\n",
    "\\sum_{i=1}^n x_i y_i \\;=\\; m\\sum_{i=1}^n x_i^2 \\;+\\; b\\sum_{i=1}^n x_i.\n",
    "$$\n",
    "Substitute ($b=\\bar y - m\\bar x$):\n",
    "$$\n",
    "\\sum_{i=1}^n x_i y_i\n",
    "\\;=\\; m\\sum_{i=1}^n x_i^2 \\;+\\; (\\bar y - m\\bar x)\\sum_{i=1}^n x_i\n",
    "\\;=\\; m\\sum_{i=1}^n x_i^2 \\;+\\; n\\bar x\\bar y \\;-\\; m\\,n\\bar x^2.\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\quad\\Rightarrow\\quad\n",
    "m\\Big(\\sum_{i=1}^n x_i^2 - n\\bar x^2\\Big)\n",
    "\\;=\\; \\sum_{i=1}^n x_i y_i - n\\bar x\\bar y.\n",
    "$$\n",
    "\n",
    "Now, the sum of the left hand side can be written as: \n",
    "$$\\sum_{i=1}^n (x_i-\\bar x)^2= \\sum_{i=1}^n \\big(x_i^2 - 2\\bar x\\,x_i + \\bar x^2\\big)$$\n",
    "$$ = \\sum_{i=1}^n x_i^2 - 2\\bar x\\sum_{i=1}^n x_i + \\sum_{i=1}^n \\bar x^2$$\n",
    "$$= \\sum_{i=1}^n x_i^2 - 2\\bar x\\,(n\\bar x) + n\\bar x^2= \\sum_{i=1}^n x_i^2 - n\\bar x^2.$$\n",
    "\n",
    "and, the sum one the right hand side can be written as: \n",
    "$$\\sum_{i=1}^n (x_i-\\bar x)(y_i-\\bar y)= \\sum_{i=1}^n \\big(x_i y_i - x_i\\bar y - \\bar x y_i + \\bar x\\bar y\\big)$$ \n",
    "$$= \\sum_{i=1}^n x_i y_i \\;-\\; \\bar y\\sum_{i=1}^n x_i \\;-\\; \\bar x\\sum_{i=1}^n y_i \\;+\\; \\sum_{i=1}^n \\bar x\\bar y$$\n",
    "$$= \\sum_{i=1}^n x_i y_i - \\bar y\\,(n\\bar x) - \\bar x\\,(n\\bar y) + n\\bar x\\bar y= \\sum_{i=1}^n x_i y_i - n\\bar x\\bar y$$\n",
    "\n",
    "That is, \n",
    "$$\n",
    "\\sum_{i=1}^n(x_i-\\bar x)^2 = \\sum_{i=1}^n x_i^2 - n\\bar x^2,\\qquad\n",
    "\\sum_{i=1}^n(x_i-\\bar x)(y_i-\\bar y) = \\sum_{i=1}^n x_i y_i - n\\bar x\\bar y.\n",
    "$$\n",
    "Therefore, substituting back, we get:\n",
    "$$\n",
    "\\boxed{\\,m\n",
    "= \\frac{\\sum_{i=1}^n (x_i-\\bar x)(y_i-\\bar y)}\n",
    "       {\\sum_{i=1}^n (x_i-\\bar x)^2}\\,},\\qquad\n",
    "\\boxed{\\,b=\\bar y - m\\bar x\\,}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbcedb6-5ca8-4fef-9c65-da24bf104f6f",
   "metadata": {},
   "source": [
    "## Implementation of the closed-form Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9747d300-5257-424e-b154-a6eda5348429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Iterable\n",
    "\n",
    "class CustomLR:\n",
    "    \"\"\"\n",
    "    Simple univariate (1D) linear regression using the closed-form OLS solution.\n",
    "    y = m * x + b\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.m = None\n",
    "        self.b = None\n",
    "        self.x_bar = None\n",
    "        self.y_bar = None\n",
    "\n",
    "    def fit(self, X_train: Iterable[float], y_train: Iterable[float]):\n",
    "        \n",
    "        ''' Fit the linear regression model to 1D data. '''\n",
    "        \n",
    "        X = np.asarray(X_train, dtype=float)\n",
    "        y = np.asarray(y_train, dtype=float)\n",
    "\n",
    "        # input validation \n",
    "        if X.size == 0 or y.size == 0:\n",
    "            raise ValueError(\"X_train and y_train must be non-empty.\")\n",
    "        if X.size != y.size:\n",
    "            raise ValueError(\"X_train and y_train must have the same length.\")\n",
    "        if X.ndim != 1 or y.ndim != 1:\n",
    "            raise ValueError(\"CustomLR supports only 1D inputs.\")\n",
    "        if not np.isfinite(X).all() or not np.isfinite(y).all():\n",
    "            raise ValueError(\"Inputs contain NaN or infinite values.\")\n",
    "\n",
    "        # compute slope and intercept \n",
    "        self.x_bar, self.y_bar = X.mean(), y.mean()\n",
    "        X_c, y_c = X - self.x_bar, y - self.y_bar\n",
    "\n",
    "        denom = np.dot(X_c, X_c)\n",
    "        if denom == 0.0:\n",
    "            raise ValueError(\"All X values are identical; slope is undefined.\")\n",
    "\n",
    "        self.m = np.dot(X_c, y_c) / denom\n",
    "        self.b = self.y_bar - self.m * self.x_bar\n",
    "        return self\n",
    "\n",
    "    def predict(self, X_test: Iterable[float]) -> np.ndarray:\n",
    "        \"\"\"Predict outputs for new 1D input data.\"\"\"\n",
    "        if self.m is None or self.b is None:\n",
    "            raise ValueError(\"Model is not fitted yet. Call fit() first.\")\n",
    "\n",
    "        X = np.asarray(X_test, dtype=float)\n",
    "        if X.ndim != 1:\n",
    "            raise ValueError(\"CustomLR supports only 1D inputs.\")\n",
    "        return self.m * X + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a9a2532-f906-48be-82e1-d19d6e4fee4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cgpa</th>\n",
       "      <th>package</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.89</td>\n",
       "      <td>3.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.12</td>\n",
       "      <td>1.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.82</td>\n",
       "      <td>3.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.42</td>\n",
       "      <td>3.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.94</td>\n",
       "      <td>3.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cgpa  package\n",
       "0  6.89     3.26\n",
       "1  5.12     1.98\n",
       "2  7.82     3.25\n",
       "3  7.42     3.67\n",
       "4  6.94     3.57"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/placement.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ed15de8-bad0-47ee-b61d-6d995a735ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 0].values\n",
    "y = df.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0209d79-4d31-4b76-8dc2-16011418aa62",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.89, 5.12, 7.82, 7.42, 6.94, 7.89, 6.73, 6.75, 6.09, 8.31, 5.32,\n",
       "       6.61, 8.94, 6.93, 7.73, 7.25, 6.84, 5.38, 6.94, 7.48, 7.28, 6.85,\n",
       "       6.14, 6.19, 6.53, 7.28, 8.31, 5.42, 5.94, 7.15, 7.36, 8.1 , 6.96,\n",
       "       6.35, 7.34, 6.87, 5.99, 5.9 , 8.62, 7.43, 9.38, 6.89, 5.95, 7.66,\n",
       "       5.09, 7.87, 6.07, 5.84, 8.63, 8.87, 9.58, 9.26, 8.37, 6.47, 6.86,\n",
       "       8.2 , 5.84, 6.6 , 6.92, 7.56, 5.61, 5.48, 6.34, 9.16, 7.36, 7.6 ,\n",
       "       5.11, 6.51, 7.56, 7.3 , 5.79, 7.47, 7.78, 8.44, 6.85, 6.97, 6.94,\n",
       "       8.99, 6.59, 7.18, 7.63, 6.1 , 5.58, 8.44, 4.26, 4.79, 7.61, 8.09,\n",
       "       4.73, 6.42, 7.11, 6.22, 7.9 , 6.79, 5.83, 6.63, 7.11, 5.98, 7.69,\n",
       "       6.61, 7.95, 6.71, 5.13, 7.05, 7.62, 6.66, 6.13, 6.33, 7.76, 7.77,\n",
       "       8.18, 5.42, 8.58, 6.94, 5.84, 8.35, 9.04, 7.12, 7.4 , 7.39, 5.23,\n",
       "       6.5 , 5.12, 5.1 , 6.06, 7.33, 5.91, 6.78, 7.93, 7.29, 6.68, 6.37,\n",
       "       5.84, 6.05, 7.2 , 6.1 , 5.64, 7.14, 7.91, 7.19, 7.91, 6.76, 6.93,\n",
       "       4.85, 6.17, 5.84, 6.07, 5.66, 7.57, 8.28, 6.3 , 6.12, 7.37, 7.94,\n",
       "       7.08, 6.98, 7.38, 6.47, 5.95, 8.71, 7.13, 7.3 , 5.53, 8.93, 9.06,\n",
       "       8.21, 8.6 , 8.13, 8.65, 9.31, 6.22, 8.01, 6.93, 6.75, 7.32, 7.04,\n",
       "       6.29, 7.09, 8.15, 7.14, 6.19, 8.22, 5.88, 7.28, 7.88, 6.31, 7.84,\n",
       "       6.26, 7.35, 8.11, 6.19, 7.28, 8.25, 4.57, 7.89, 6.93, 5.89, 7.21,\n",
       "       7.63, 6.22])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c8d1f7d-5a87-493e-96a7-bdd1a1d256a1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.26, 1.98, 3.25, 3.67, 3.57, 2.99, 2.6 , 2.48, 2.31, 3.51, 1.86,\n",
       "       2.6 , 3.65, 2.89, 3.42, 3.23, 2.35, 2.09, 2.98, 2.83, 3.16, 2.93,\n",
       "       2.3 , 2.48, 2.71, 3.65, 3.42, 2.16, 2.24, 3.49, 3.26, 3.89, 3.08,\n",
       "       2.73, 3.42, 2.87, 2.84, 2.43, 4.36, 3.33, 4.02, 2.7 , 2.54, 2.76,\n",
       "       1.86, 3.58, 2.26, 3.26, 4.09, 4.62, 4.43, 3.79, 4.11, 2.61, 3.09,\n",
       "       3.39, 2.74, 1.94, 3.09, 3.31, 2.19, 1.61, 2.09, 4.25, 2.92, 3.81,\n",
       "       1.63, 2.89, 2.99, 2.94, 2.35, 3.34, 3.62, 4.03, 3.44, 3.28, 3.15,\n",
       "       4.6 , 2.21, 3.  , 3.44, 2.2 , 2.17, 3.49, 1.53, 1.48, 2.77, 3.55,\n",
       "       1.48, 2.72, 2.66, 2.14, 4.  , 3.08, 2.42, 2.79, 2.61, 2.84, 3.83,\n",
       "       3.24, 4.14, 3.52, 1.37, 3.  , 3.74, 2.82, 2.19, 2.59, 3.54, 4.06,\n",
       "       3.76, 2.25, 4.1 , 2.37, 1.87, 4.21, 3.33, 2.99, 2.88, 2.65, 1.73,\n",
       "       3.02, 2.01, 2.3 , 2.31, 3.16, 2.6 , 3.11, 3.34, 3.12, 2.49, 2.01,\n",
       "       2.48, 2.58, 2.83, 2.6 , 2.1 , 3.13, 3.89, 2.4 , 3.15, 3.18, 3.04,\n",
       "       1.54, 2.42, 2.18, 2.46, 2.21, 3.4 , 3.67, 2.73, 2.76, 3.08, 3.99,\n",
       "       2.85, 3.09, 3.13, 2.7 , 3.04, 4.08, 2.93, 3.33, 2.55, 3.91, 3.82,\n",
       "       4.08, 3.98, 3.6 , 3.52, 4.37, 2.87, 3.76, 2.51, 2.56, 2.99, 3.5 ,\n",
       "       3.23, 3.64, 3.63, 3.03, 2.72, 3.89, 2.08, 2.72, 3.14, 3.18, 3.47,\n",
       "       2.44, 3.08, 4.06, 2.69, 3.48, 3.75, 1.94, 3.67, 2.46, 2.57, 3.24,\n",
       "       3.96, 2.33])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e93e049f-9ed6-4721-9378-992f898c530d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "299cf1a3-515e-4192-b433-c6220fe73367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.CustomLR at 0x224d60c6120>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1 = CustomLR()\n",
    "lr1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3aab9ae2-5b70-4993-9569-979f39e41562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3.89111601]), array([4.1]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1.predict(X_test[[0]]), y_test[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd1547e-b272-4807-90d7-4b93eeb8b5e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
